#!/usr/bin/env mantidpython

import mantid.simpleapi as api
from mantid.kernel import DateAndTime
from Core import FindData
import MCPL
import numpy as np
import time as measureTime
from pathlib import Path
from datetime import datetime

import os

#mcStasFolderName, mcplFileName, saveFileName = ("flat_col5_5bs3_10bs5_split1e4_1e10_acc50", "flatSample/col5_acc50_rearBank5m_rear5/col5_acc50_rearBank5m_rear5.mcpl", "SavedNexusFile.nxs")
#mcStasFolderName, mcplFileName, saveFileName, rear = ("flat_col5_5bs3_10bs5_split1e5_1e11_acc5k", "flatSample/col5_acc5k_rearBank5m_rear5/col5_acc5k_rearBank5m_rear5.mcpl", "SavedNexusFile_5k.nxs", 5)
#mcStasFolderName, mcplFileName, saveFileName, rear = ("samp18_col3_5bs5_10bs5_split1e4_1e11_acc500", "sample18/col3_acc500_frontMidBanks_rear5/col3_acc500_frontMidBanks_rear5.mcpl", "col3_acc500_frontMidBanks_rear5.nxs", 5)

#mcStasFolderName = "flat_col5_5bs3_10bs5_split1e4_1e10_acc50"
#mcplFileNameList = ["floodSource/floodSource_0to999.mcpl", "floodSource/floodSource_1000to1999.mcpl", "floodSource/floodSource_2000to2999.mcpl", "floodSource/floodSource_3000to3999.mcpl", "floodSource/floodSource_4000to4999.mcpl"]
#mcplFileNameList = ["floodSource/floodSource_5000to5999.mcpl", "floodSource/floodSource_6000to6999.mcpl", "floodSource/floodSource_7000to7999.mcpl", "floodSource/floodSource_8000to8999.mcpl", "floodSource/floodSource_9000to9999.mcpl"]
#mcplFileNameList = ["floodSource_air/floodSource_air0-999.mcpl"] #, "floodSource2/floodSource16000-16999.mcpl"]

mcplFileNameList =  ["wrongSsd/floodSource_ssd4420/detectionEvents.mcpl"]
numberOfMCPLFiles = len(mcplFileNameList)
saveFileName = "test_wrongSsd_floodSource_ssd4420.nxs"

mcplBaseDir_larmor = Path(os.environ.get('G4PROC_MCPL_BASEDIR_LARMOR2020', None))
saveDir_larmor = Path(os.environ.get('G4PROC_SAVEDIR_LARMOR2020', None))

mcplFileList = [ mcplBaseDir_larmor / mcplFileName  for mcplFileName in mcplFileNameList]
saveFile = str(saveDir_larmor / saveFileName)

instrumentDefinitionFile = FindData("LokiMantid","LARMOR_Definition_2020.xml")

def createTofSpectrum(numberOfFiles):
    t_min = 12770 #tof(lambda=2AA)=12791
    t_max = 83007 #tof(lambda=13AA)=83139
    numberOfBins = t_max-t_min
    spectrumMax = 100000

    intensityPerFile = 1e10 #1e7*1000
    directionBiasIntensityFactor = 120
    realSourceIntensity = numberOfFiles * intensityPerFile * directionBiasIntensityFactor

    tof = np.zeros(spectrumMax)
    intensity = np.zeros(spectrumMax)
    error = np.zeros(spectrumMax)

    hardcoded_value = round(realSourceIntensity / numberOfBins)
    hardcoded_error = round(np.sqrt(hardcoded_value)) #roundind probably not needed
    print(f'CHECK: Hardcoded McStas value = {hardcoded_value}')
    debug = 0
    
    for i in range(spectrumMax): #(time,value,err) in enumerate(zip(tof, intensity, error)):
        tof[i] = i
        if i >= t_min and i < t_max:
            intensity[i] = hardcoded_value
            error[i] = hardcoded_error
            debug = debug + 1
        else:
            intensity[i] = 0
            error[i] = 0

    #print("DEBUG: number of McStas binst with intensity: " + str(debug))
    print(f'CHECK: Sum intensity in McStas: {debug * hardcoded_value}')
    return tof, intensity, error

startScriptTime = measureTime.time()
# do stuff


print("Create Incident spectrum on sample - START")

X = []
Y = []
E = []
detIDs = []

tof, y, e = createTofSpectrum(numberOfMCPLFiles)

X.append(tof)
Y.append(y)
E.append(e)

X = np.array(X)
Y = np.array(Y)
E = np.array(E)
mcStasMonitorWS = api.CreateWorkspace(OutputWorkspace="mcStasMonitorWS", DataX=X, DataY=Y, DataE=E, NSpec=1, UnitX='TOF', YUnitLabel='Counts')

api.LoadInstrument(Workspace=mcStasMonitorWS, Filename=instrumentDefinitionFile, RewriteSpectraMap=True)

print("Create Incident spectrum on sample - END")


print("Process Geant4 data - START")

Geant4DataWS = api.LoadEmptyInstrument(instrumentDefinitionFile, MakeEventWorkspace=True)

numHists = Geant4DataWS.getNumberHistograms()
detToIndex = {}
for i in range(numHists):
    eventList = Geant4DataWS.getSpectrum(i)
    id = eventList.getDetectorIDs()
    detToIndex[id[0]] = i
    eventList.clear(False)


pulsetime = datetime.now()
        
dateTime = DateAndTime(pulsetime.isoformat(sep="T"))
numHistograms = Geant4DataWS.getNumberHistograms()

allEventList = [ Geant4DataWS.getSpectrum(idx) for idx in range(numHistograms)]

#tof = np.array([])
#detids = np.array([])

readBlockLength = 100000000

idOffset = 0

print("Loading detection events from MCPL - START")

countAddEventError = 0
globalCountEventError = 0

for mcplFile in mcplFileList:
    countAddEventError = 0
    tof = np.array([])
    detids = np.array([])
    myfile = MCPL.MCPLFile(mcplFile, blocklength=readBlockLength)
    with myfile:
        for p in myfile.particle_blocks:
            detids = np.append(detids, p.userflags.astype(int))
            tof = np.append(tof, p.time * 1000.0)  # convert to microseconds
        
        print(f"Loading detection events from MCPL {mcplFile} - END")

        print("Add events to workspace - START")
        for time,detId in zip(tof, detids):
            try:
                allEventList[detToIndex[detId+idOffset]].addEventQuickly(time, dateTime)
            except:
                countAddEventError = countAddEventError + 1
                #print('Index problem: ' + str(detId) + ' withOffset: ' + str(detId+idOffset) )
                pass

        globalCountEventError = globalCountEventError + countAddEventError 
        print(f'Number of addEventQuickly errors in file {mcplFile} is: {countAddEventError}')
        print("Add events to workspace - END")
        
print(f'SUM number of addEventQuickly errors: {globalCountEventError}')
tofmin = int(Geant4DataWS.getTofMin())
tofmax = int(Geant4DataWS.getTofMax())
#print('tofmin', tofmin)
#print('tofmax', tofmax)
width = tofmax - tofmin
#width = (tofmax - tofmin)/100 #milan
ptMin = Geant4DataWS.getPulseTimeMin()
ptMax = Geant4DataWS.getPulseTimeMax()

run = Geant4DataWS.run()
run.setStartAndEndTime(ptMin, ptMax)
run.addProperty("run_number", "1", True)
run.addProperty("run_start", str(ptMin), True)
run.addProperty("TimeUnit", "Micro Seconds", True)
#SortEvents(InputWorkspace=Geant4DataWS, SortBy='Pulse Time')
#Geant4DataWS = Rebin(InputWorkspace=Geant4DataWS, OutputWorkspace=Geant4DataWS,
#             Params=str(tofmin) + "," + str(width) + "," + str(tofmax), PreserveEvents=True)
Geant4DataWS.setYUnitLabel("Counts")
Geant4DataWS.getAxis(0).setUnit("TOF")

print("Process Geant4 data - END")    

tofHistogramStart = 5 # [microSeconds]
tofHistogramBinwidth = 100 # [microSeconds]
tofHistogramEnd = 100000 # [microSeconds]
params = [tofHistogramStart, tofHistogramBinwidth, tofHistogramEnd]

if (tofmin < tofHistogramStart):
    print("WARNING: tofmin is lower than the histogram limit")
if (tofmax > tofHistogramEnd):
    print("WARNING: tofmax is higher than the histogram limit")
    
Geant4DataWS2D = api.Rebin(InputWorkspace=Geant4DataWS, OutputWorkspace='Geant4DataWS2D', Params=params, PreserveEvents=False)
mcStasMonitorWS_rebin = api.Rebin(InputWorkspace=mcStasMonitorWS, OutputWorkspace='mcStasMonitorWS_rebin', Params=params)

# Copy Monitor Data into Geant4DataWS workspace
gw = api.mtd['Geant4DataWS2D']
mw = api.mtd['mcStasMonitorWS_rebin']
gw.setY(2, mw.readY(0))
 
#for i in range(4):
#    gw.setY(i, mw.readY(i))


# Save nexus file
api.SaveNexus(Geant4DataWS2D, saveFile)
print(f'Saved Nexus file: {saveFile}')

elapsed = measureTime.time() - startScriptTime
print(elapsed)

# Not sure, if needed
#DeleteWorkspace(Workspace=mcStasMonitorWS)
#DeleteWorkspace(Workspace=Geant4DataWS)
